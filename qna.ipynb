{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46700a40-1b50-42bc-ae13-5f9b7a304877",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-13T14:07:51.318145Z",
     "iopub.status.busy": "2024-09-13T14:07:51.317852Z",
     "iopub.status.idle": "2024-09-13T14:07:58.776743Z",
     "shell.execute_reply": "2024-09-13T14:07:58.776015Z",
     "shell.execute_reply.started": "2024-09-13T14:07:51.318119Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-13 19:37:55.027921: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-13 19:37:55.051720: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-13 19:37:55.060019: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-13 19:37:55.079655: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-13 19:37:56.553275: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset as TorchDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ffc958",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Load your custom dataset from CSV\n",
    "df = pd.read_csv(\"/home/dnn/Storage8TB/pythonCodeArea/srijita/Text/qna_output.csv\")\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c8d5de5-a7c5-4abc-86cc-11b5bab26b63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-13T14:08:11.244580Z",
     "iopub.status.busy": "2024-09-13T14:08:11.244209Z",
     "iopub.status.idle": "2024-09-13T14:08:11.256787Z",
     "shell.execute_reply": "2024-09-13T14:08:11.254133Z",
     "shell.execute_reply.started": "2024-09-13T14:08:11.244552Z"
    }
   },
   "outputs": [],
   "source": [
    "# Custom Dataset class to handle labels\n",
    "class CustomDataset(TorchDataset):\n",
    "    def __init__(self, input_ids, attention_mask, start_positions, end_positions):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_mask = attention_mask\n",
    "        self.start_positions = start_positions\n",
    "        self.end_positions = end_positions\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.input_ids[idx],\n",
    "            'attention_mask': self.attention_mask[idx],\n",
    "            'start_positions': self.start_positions[idx],\n",
    "            'end_positions': self.end_positions[idx]\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37ed2cf3-5ba3-41d4-8412-80020899de0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-13T14:08:28.691051Z",
     "iopub.status.busy": "2024-09-13T14:08:28.690612Z",
     "iopub.status.idle": "2024-09-13T14:08:28.698856Z",
     "shell.execute_reply": "2024-09-13T14:08:28.697920Z",
     "shell.execute_reply.started": "2024-09-13T14:08:28.691025Z"
    }
   },
   "outputs": [],
   "source": [
    "# Custom Data Collator\n",
    "class CustomDataCollator:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, features):\n",
    "        batch = {key: torch.stack([f[key] for f in features]) for key in features[0].keys()}\n",
    "        return batch\n",
    "\n",
    "# Load models and tokenizers\n",
    "def load_models_and_tokenizers():\n",
    "    qa_model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-cased-distilled-squad\")\n",
    "    qa_tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-cased-distilled-squad\")\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        qa_model = qa_model.to(\"cuda\")\n",
    "\n",
    "    return qa_model, qa_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f09e2018-0a5d-49b4-8f86-5a37b928ec86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-13T14:10:21.382925Z",
     "iopub.status.busy": "2024-09-13T14:10:21.381933Z",
     "iopub.status.idle": "2024-09-13T14:10:21.387977Z",
     "shell.execute_reply": "2024-09-13T14:10:21.387291Z",
     "shell.execute_reply.started": "2024-09-13T14:10:21.382891Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocess the dataset\n",
    "def preprocess_function(examples, qa_tokenizer):\n",
    "    inputs = examples['text']\n",
    "    answers = examples['answer']\n",
    "    \n",
    "    model_inputs = qa_tokenizer(inputs, max_length=256, truncation=True, padding=\"max_length\")\n",
    "    \n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i in range(len(inputs)):\n",
    "        context = inputs[i]\n",
    "        answer = answers[i]\n",
    "        \n",
    "        start, end = find_answer_positions(context, answer, qa_tokenizer)\n",
    "        start_positions.append(start)\n",
    "        end_positions.append(end)\n",
    "\n",
    "    return {\n",
    "        'input_ids': model_inputs['input_ids'],\n",
    "        'attention_mask': model_inputs['attention_mask'],\n",
    "        'start_positions': start_positions,\n",
    "        'end_positions': end_positions\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8ab72a4-e525-4874-8255-2eb0822eac8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-13T14:10:37.672012Z",
     "iopub.status.busy": "2024-09-13T14:10:37.671707Z",
     "iopub.status.idle": "2024-09-13T14:10:37.680331Z",
     "shell.execute_reply": "2024-09-13T14:10:37.679662Z",
     "shell.execute_reply.started": "2024-09-13T14:10:37.671985Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find start and end positions for the answers in the context\n",
    "def find_answer_positions(context, answer, tokenizer):\n",
    "    tokenized_context = tokenizer(context, add_special_tokens=False)['input_ids']\n",
    "    tokenized_answer = tokenizer(answer, add_special_tokens=False)['input_ids']\n",
    "    for i in range(len(tokenized_context) - len(tokenized_answer) + 1):\n",
    "        if tokenized_context[i:i+len(tokenized_answer)] == tokenized_answer:\n",
    "            return i, i + len(tokenized_answer) - 1\n",
    "    return 0, 0  # Default to 0,0 if answer is not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4763607e-accd-425f-9f4f-831a8dd6eae4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-13T14:11:07.007140Z",
     "iopub.status.busy": "2024-09-13T14:11:07.003396Z",
     "iopub.status.idle": "2024-09-13T14:11:07.016125Z",
     "shell.execute_reply": "2024-09-13T14:11:07.015388Z",
     "shell.execute_reply.started": "2024-09-13T14:11:07.004536Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model with user-defined parameters\n",
    "def train_model(model, tokenizer, train_dataset, valid_dataset, epochs, batch_size, learning_rate):\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=epochs,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=valid_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=CustomDataCollator(tokenizer),\n",
    "    )\n",
    "\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698bfd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate answers based on context and question\n",
    "def generate_answer(context, question, qa_model, qa_tokenizer):\n",
    "    inputs = qa_tokenizer.encode_plus(question, context, return_tensors='pt', max_length=512, truncation=True)\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = {k: v.to('cuda') for k, v in inputs.items()}\n",
    "\n",
    "    outputs = qa_model(**inputs)\n",
    "    answer_start = torch.argmax(outputs.start_logits)\n",
    "    answer_end = torch.argmax(outputs.end_logits) + 1\n",
    "    return qa_tokenizer.convert_tokens_to_string(qa_tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e831afe5-8858-4534-9c88-f5e726ab8c37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-13T14:11:29.593723Z",
     "iopub.status.busy": "2024-09-13T14:11:29.593402Z",
     "iopub.status.idle": "2024-09-13T14:11:30.706469Z",
     "shell.execute_reply": "2024-09-13T14:11:30.705431Z",
     "shell.execute_reply.started": "2024-09-13T14:11:29.593699Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dnn/.local/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/home/dnn/.local/lib/python3.12/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load models and tokenizers\n",
    "    qa_model, qa_tokenizer = load_models_and_tokenizers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e74fbe26-938f-4bd1-b3d6-72904e2626f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-13T14:12:03.792214Z",
     "iopub.status.busy": "2024-09-13T14:12:03.791945Z",
     "iopub.status.idle": "2024-09-13T14:12:04.574027Z",
     "shell.execute_reply": "2024-09-13T14:12:04.573169Z",
     "shell.execute_reply.started": "2024-09-13T14:12:03.792194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599bf13250fb4764919a79b66d025f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d031473053a4b90b11ca8c551f21a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "train_test_split = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "# Preprocess dataset\n",
    "train_dataset = train_test_split['train'].map(lambda x: preprocess_function(x, qa_tokenizer), batched=True)\n",
    "valid_dataset = train_test_split['test'].map(lambda x: preprocess_function(x, qa_tokenizer), batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b1564dc-07a2-41c6-8d2d-47e832f7c240",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-13T14:12:24.280483Z",
     "iopub.status.busy": "2024-09-13T14:12:24.279504Z",
     "iopub.status.idle": "2024-09-13T14:12:24.325127Z",
     "shell.execute_reply": "2024-09-13T14:12:24.324446Z",
     "shell.execute_reply.started": "2024-09-13T14:12:24.280450Z"
    }
   },
   "outputs": [],
   "source": [
    "  # Convert to PyTorch Dataset\n",
    "train_torch_dataset = CustomDataset(\n",
    "    input_ids=torch.tensor(train_dataset['input_ids']),\n",
    "    attention_mask=torch.tensor(train_dataset['attention_mask']),\n",
    "    start_positions=torch.tensor(train_dataset['start_positions']),\n",
    "    end_positions=torch.tensor(train_dataset['end_positions'])\n",
    ")\n",
    "\n",
    "valid_torch_dataset = CustomDataset(\n",
    "    input_ids=torch.tensor(valid_dataset['input_ids']),\n",
    "    attention_mask=torch.tensor(valid_dataset['attention_mask']),\n",
    "    start_positions=torch.tensor(valid_dataset['start_positions']),\n",
    "    end_positions=torch.tensor(valid_dataset['end_positions'])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "172057e0-995b-478b-bbbd-3308c7116041",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-13T14:12:57.926659Z",
     "iopub.status.busy": "2024-09-13T14:12:57.926341Z",
     "iopub.status.idle": "2024-09-13T14:37:13.708802Z",
     "shell.execute_reply": "2024-09-13T14:37:13.708288Z",
     "shell.execute_reply.started": "2024-09-13T14:12:57.926634Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dnn/.local/lib/python3.12/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msrijitaghoshhajra9\u001b[0m (\u001b[33msrijitaghoshhajra9-college-board\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/dnn/Storage8TB/pythonCodeArea/srijita/Text/wandb/run-20240913_194301-8pq0yzdc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/srijitaghoshhajra9-college-board/huggingface/runs/8pq0yzdc' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/srijitaghoshhajra9-college-board/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/srijitaghoshhajra9-college-board/huggingface' target=\"_blank\">https://wandb.ai/srijitaghoshhajra9-college-board/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/srijitaghoshhajra9-college-board/huggingface/runs/8pq0yzdc' target=\"_blank\">https://wandb.ai/srijitaghoshhajra9-college-board/huggingface/runs/8pq0yzdc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 23:59, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.248546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.417482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.317642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.873700</td>\n",
       "      <td>1.961863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.873700</td>\n",
       "      <td>1.848046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.873700</td>\n",
       "      <td>1.886650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.623400</td>\n",
       "      <td>2.165314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.623400</td>\n",
       "      <td>2.307266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.623400</td>\n",
       "      <td>2.334587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.201700</td>\n",
       "      <td>2.186985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.201700</td>\n",
       "      <td>2.198531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.201700</td>\n",
       "      <td>2.439775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.201700</td>\n",
       "      <td>2.768685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.058700</td>\n",
       "      <td>3.005885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.058700</td>\n",
       "      <td>3.118282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.058700</td>\n",
       "      <td>3.071823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.029200</td>\n",
       "      <td>2.983405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.029200</td>\n",
       "      <td>2.975340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.029200</td>\n",
       "      <td>2.993724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>3.045303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>3.108432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>3.172112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>3.207427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>3.236734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>3.268081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>3.304627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>3.348277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>3.396603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>3.448694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>3.491171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>3.533858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>3.567932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>3.593873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>3.615302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>3.630566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>3.641810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>3.618450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>3.553006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>3.509411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>3.476132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>3.459360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>3.453007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>3.452142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>3.454709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>3.459247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>3.464388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>3.468113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>3.470958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>3.473154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>3.474113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "epochs = 50\n",
    "batch_size = 8\n",
    "learning_rate = 2e-5\n",
    "\n",
    "# Train the model\n",
    "train_model(qa_model, qa_tokenizer, train_torch_dataset, valid_torch_dataset, epochs, batch_size, learning_rate)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f517bf19-0e34-4571-97d6-f35f6f65a2c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-13T16:04:16.645166Z",
     "iopub.status.busy": "2024-09-13T16:04:16.644854Z",
     "iopub.status.idle": "2024-09-13T16:04:16.825476Z",
     "shell.execute_reply": "2024-09-13T16:04:16.824910Z",
     "shell.execute_reply.started": "2024-09-13T16:04:16.645140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input Text: I love to read. Reading is my hobby. I read books belonging to all genres. But it is adventure and mystery stories that keep me the most engaged. I enjoy reading Sherlock Holmes stories by Arthur Conan Doyle. \n",
      "Generated Question: What is my hobby?\n",
      "Generated Answer: Reading\n"
     ]
    }
   ],
   "source": [
    "# Example input text\n",
    "example_text = \"I love to read. Reading is my hobby. I read books belonging to all genres. But it is adventure and mystery stories that keep me the most engaged. I enjoy reading Sherlock Holmes stories by Arthur Conan Doyle. \"\n",
    "\n",
    "# Generate questions and answers\n",
    "question = \"What is my hobby?\"\n",
    "answer = generate_answer(example_text, question, qa_model, qa_tokenizer)\n",
    "\n",
    "# Print results\n",
    "print(f\"\\nInput Text: {example_text}\")\n",
    "print(f\"Generated Question: {question}\")\n",
    "print(f\"Generated Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f373e58-8b74-4221-b8c7-1bc3d7337dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
